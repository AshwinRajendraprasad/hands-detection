{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing inputs\n",
    "The inputs generation uses three step:\n",
    "1. Pulling data\n",
    "2. Formatting data to TFRecord files\n",
    "3. Writting TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "\n",
    "import wget\n",
    "import tarfile\n",
    "import io\n",
    "import hashlib\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"./models/\")\n",
    "sys.path.append(\"./models/object_detection\")\n",
    "\n",
    "from utils import dataset_util\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "We know the only label will be \"hand\", so the label map file is ready-to-use in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './dataset'\n",
    "\n",
    "# Test dataset\n",
    "TEST_IMG_DIR = os.path.join(DATA_PATH, 'test_dataset', 'test_data', 'images')\n",
    "TEST_ANN_DIR = os.path.join(DATA_PATH, 'test_dataset', 'test_data', 'annotations')\n",
    "TEST_OUTPUT_FILENAME = 'hands_test.record'\n",
    "\n",
    "# Training dataset\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_PATH, 'training_dataset', 'training_data', 'images')\n",
    "TRAIN_ANN_DIR = os.path.join(DATA_PATH, 'training_dataset', 'training_data', 'annotations')\n",
    "TRAIN_OUTPUT_FILENAME = 'hands_train.record'\n",
    "\n",
    "# Validation dataset\n",
    "VAL_IMG_DIR = os.path.join(DATA_PATH, 'validation_dataset', 'validation_data', 'images')\n",
    "VAL_ANN_DIR = os.path.join(DATA_PATH, 'validation_dataset', 'validation_data', 'annotations')\n",
    "VAL_OUTPUT_FILENAME = 'hands_val.record'\n",
    "\n",
    "# The label map file with the \"hand\" label\n",
    "LABEL_MAP_PATH = 'hands_label_map.pbtxt'\n",
    "label_map_dict = label_map_util.get_label_map_dict(LABEL_MAP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data from University of Oxford \"Hands Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test_dataset.tar.gz...\n",
      "Extracting test_dataset.tar.gz...\n",
      "Downloading validation_dataset.tar.gz...\n",
      "Extracting validation_dataset.tar.gz...\n",
      "Downloading training_dataset.tar.gz...\n",
      "Extracting training_dataset.tar.gz...\n",
      "CPU times: user 6.46 s, sys: 4.07 s, total: 10.5 s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "def pull_data(data_filenames):\n",
    "    # Load train, test and validation data\n",
    "    for data_filename in data_filenames:\n",
    "\n",
    "        print('Downloading %s.tar.gz...' % data_filename)\n",
    "        data_url = 'http://www.robots.ox.ac.uk/~vgg/data/hands/downloads/%s.tar.gz' % data_filename\n",
    "        data_filename_ext = wget.download(data_url)\n",
    "\n",
    "        print('Extracting %s...' % data_filename_ext)\n",
    "        data_tar = tarfile.open('%s' % data_filename_ext)\n",
    "        data_tar.extractall(path='dataset/')\n",
    "        data_tar.close()\n",
    "        \n",
    "%time pull_data(['test_dataset', 'validation_dataset', 'training_dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAT file parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coords_from_mat(mat_filepath):\n",
    "    mat = scipy.io.loadmat(mat_filepath)\n",
    "    coords = []\n",
    "    i = 0\n",
    "    for e in mat['boxes'][0]:\n",
    "        coords.append(list())\n",
    "        c = 0\n",
    "        for d in e[0][0]:\n",
    "            if c > 3:\n",
    "                break\n",
    "            coords[i].append((d[0][0], d[0][1]))\n",
    "            c += 1\n",
    "        i += 1\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting MAT files to TFRecord files\n",
    "Create a TF Example from training data name. Ex: if 'name' is 'Buffy_01', it will use Buffy_01.jpg file in IMG_PATH directory and Buffy_01.mat in ANN_PATH directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tf_example(name, img_dir, ann_dir):\n",
    "\n",
    "    IMG_FILENAME = '%s.jpg' % name\n",
    "    ANN_FILENAME = '%s.mat' % name\n",
    "    IMG_FULL_PATH = os.path.join(img_dir, IMG_FILENAME)\n",
    "    ANN_FULL_PATH = os.path.join(ann_dir, ANN_FILENAME)\n",
    "\n",
    "    with tf.gfile.GFile(IMG_FULL_PATH, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    label = 'hand'\n",
    "    width, height = image.size\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    poses = []\n",
    "    difficult_obj = []\n",
    "\n",
    "    coords = coords_from_mat(ANN_FULL_PATH)\n",
    "\n",
    "    for coord in coords:\n",
    "\n",
    "        x_max, x_min, y_max, y_min = 0, float('inf'), 0, float('inf')\n",
    "        for y,x in coord:\n",
    "            x_max, x_min = max(x, x_max), min(x, x_min)\n",
    "            y_max, y_min = max(y, y_max), min(y, y_min) \n",
    "\n",
    "        xmin.append(max(float(x_min) / width, 0.0))\n",
    "        ymin.append(max(float(y_min) / height, 0.0))\n",
    "        xmax.append(min(float(x_max) / width, 1.0))\n",
    "        ymax.append(min(float(y_max) / height, 1.0))\n",
    "        classes_text.append(label.encode('utf8'))\n",
    "        classes.append(label_map_dict[label])\n",
    "        truncated.append(0)\n",
    "        poses.append('Frontal'.encode('utf8'))\n",
    "        difficult_obj.append(0)\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(\n",
    "              IMG_FILENAME.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(\n",
    "              IMG_FILENAME.encode('utf8').encode('utf8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "        'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "        'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "        'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "      }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writting TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tf_record(img_dir, ann_dir, output_filename):\n",
    "    writer = tf.python_io.TFRecordWriter(output_filename)\n",
    "    print('Generating %s file...' % output_filename)\n",
    "    for f in os.listdir(img_dir):\n",
    "        if '.jpg' in f:\n",
    "            img_name = f.split('.')[0]\n",
    "            tf_example = create_tf_example(img_name, img_dir, ann_dir)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('%s written.' % output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hands_train.record file...\n",
      "hands_train.record written.\n",
      "Generating hands_val.record file...\n",
      "hands_val.record written.\n",
      "Generating hands_test.record file...\n",
      "hands_test.record written.\n"
     ]
    }
   ],
   "source": [
    "create_tf_record(TRAIN_IMG_DIR, TRAIN_ANN_DIR, TRAIN_OUTPUT_FILENAME)\n",
    "create_tf_record(VAL_IMG_DIR, VAL_ANN_DIR, VAL_OUTPUT_FILENAME)\n",
    "create_tf_record(TEST_IMG_DIR, TEST_ANN_DIR, TEST_OUTPUT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
